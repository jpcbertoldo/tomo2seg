{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import dataclasses\n",
    "import functools\n",
    "import gc\n",
    "import itertools\n",
    "import logging\n",
    "import operator\n",
    "import pprint as pprint_module\n",
    "import time\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import humanize\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from cnn_segm import keras_custom_loss\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy.random import RandomState\n",
    "from progressbar import progressbar as pbar\n",
    "from pymicro.file import file_utils\n",
    "import socket\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from tomo2seg.process import ProcessVolumeArgs as Args, reduce_dimensions \n",
    "from tomo2seg import viz\n",
    "from tomo2seg.data import EstimationVolume\n",
    "from tomo2seg.data import Volume\n",
    "from tomo2seg.logger import add_file_handler as logger_add_file_handler\n",
    "from tomo2seg.logger import logger\n",
    "from tomo2seg.model import Model as Tomo2SegModel\n",
    "from tomo2seg import utils as tomo2seg_utils\n",
    "from tomo2seg import slackme\n",
    "from tomo2seg import slack\n",
    "from tomo2seg import volume_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this registers a custom exception handler for the whole current notebook\n",
    "get_ipython().set_custom_exc((Exception,), slackme.custom_exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!find ../data/models -maxdepth 1 -type d -exec ls \"{}\" \\; | grep -v hdf5 \n",
    "# print all available models' names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "manual-input"
    ]
   },
   "outputs": [],
   "source": [
    "from tomo2seg.datasets import (\n",
    "    VOLUME_COMPOSITE_V1 as VOLUME_NAME_VERSION,\n",
    "#     VOLUME_COMPOSITE_V1_REDUCED as VOLUME_NAME_VERSION,\n",
    "#     VOLUME_COMPOSITE_NEIGHBOUR as VOLUME_NAME_VERSION,    \n",
    "#     VOLUME_COMPOSITE_FLEX as VOLUME_NAME_VERSION,    \n",
    "#     VOLUME_COMPOSITE_BIAXE as VOLUME_NAME_VERSION,    \n",
    "#     VOLUME_FRACTURE00_SEGMENTED00 as VOLUME_NAME_VERSION,\n",
    ")\n",
    "\n",
    "\n",
    "args = Args.setup00_process_test(\n",
    "    # 2.5d\n",
    "#     model_type = Args.ModelType.input2halfd, \n",
    "    # done\n",
    "#     model_name = \"unet2halfd.vanilla03-f16.fold000.1606-683-705\",\n",
    "#     model_name = \"unet2halfd-sep.vanilla03-f16.fold000.1606-729-672\",\n",
    "#     model_name = \"unet2halfd.crop112-f16.fold000.1607-788-628\",\n",
    "#     model_name = \"unet2halfd-sep.crop112-f16.fold000.1607-789-290\",\n",
    "    # todo\n",
    "    \n",
    "    # 3d\n",
    "#     model_type = Args.ModelType.input3d, \n",
    "    # done\n",
    "#     model_name = \"unet3d.crop96-f08.fold000.1607-109-265\",\n",
    "    # todo\n",
    "#     model_name = \"unet3d.crop112-f12.fold000.1607-466-349\",\n",
    "#     model_name = \"unet3d.crop304-f16.fold000.1607-790-699\",\n",
    "    \n",
    "    # 2d\n",
    "    model_type = Args.ModelType.input2d, \n",
    "    # done\n",
    "    # todo\n",
    "#     model_name = \"unet2d.crop48-f16.fold000.1607-530-580\",\n",
    "    model_name = \"unet2d.crop112-f16.fold000.1607-533-765\",\n",
    "\n",
    "    volume_name=VOLUME_NAME_VERSION[0], \n",
    "    volume_version=VOLUME_NAME_VERSION[1], \n",
    "#     runid = 1607616782,  # default is time.time()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build `tomo2seg` objects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tomo2seg_model = Tomo2SegModel.build_from_model_name(args.model_name)\n",
    "\n",
    "volume = Volume.with_check(\n",
    "    name=args.volume_name, \n",
    "    version=args.volume_version\n",
    ")\n",
    "\n",
    "partition = volume[args.partition_alias] if args.partition_alias is not None else None\n",
    "\n",
    "estimation_volume = EstimationVolume.from_objects(\n",
    "    volume=volume, \n",
    "    model=tomo2seg_model, \n",
    "    set_partition=partition,\n",
    "    runid=args.runid,\n",
    ")\n",
    "\n",
    "if args.opts.save_logs:\n",
    "    logger_add_file_handler(logger, estimation_volume.exec_log_path)\n",
    "\n",
    "# this is informal metadata for human use\n",
    "estimation_volume[\"args\"] = dataclasses.asdict(args)\n",
    "estimation_volume[\"hostname\"] = hostname = socket.gethostname()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"args\\n{pprint_module.PrettyPrinter(indent=4, compact=False).pformat(dataclasses.asdict(args))}\")\n",
    "logger.info(f\"{estimation_volume=}\")\n",
    "logger.info(f\"{estimation_volume.fullname=}\")\n",
    "logger.info(f\"{estimation_volume.dir=}\")\n",
    "            \n",
    "logger.debug(f\"{volume=}\")\n",
    "logger.debug(f\"{partition=}\")\n",
    "logger.debug(f\"{tomo2seg_model=}\")\n",
    "logger.debug(f\"{tomo2seg_model.name=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(logging.DEBUG)\n",
    "random_state = np.random.RandomState(args.random_state_seed)\n",
    "\n",
    "n_gpus = len(tf.config.list_physical_devices('GPU'))\n",
    "estimation_volume[\"n_gpus\"] = n_gpus\n",
    "    \n",
    "tf_version = tf.__version__\n",
    "logger.info(f\"{tf_version=}\")\n",
    "estimation_volume[\"tf_version\"] = tf_version\n",
    "\n",
    "logger.info(f\"Num GPUs Available: {n_gpus}\\nThis should be:\\n\\t\" + '\\n\\t'.join(['2 on R790-TOMO', '1 on akela', '1 on hathi', '1 on krilin']))\n",
    "\n",
    "logger.debug(\n",
    "    \"physical GPU devices:\\n\\t\" + \"\\n\\t\".join(map(str, tf.config.list_physical_devices('GPU'))) + \"\\n\" +\n",
    "    \"logical GPU devices:\\n\\t\" + \"\\n\\t\".join(map(str, tf.config.list_logical_devices('GPU'))) \n",
    ")\n",
    "\n",
    "# xla auto-clustering optimization (see: https://www.tensorflow.org/xla#auto-clustering)\n",
    "# this seems to break the training\n",
    "tf.config.optimizer.set_jit(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "figure out the gpu's limitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an estimate of how much the gpu can take\n",
    "MAX_INTERNAL_NVOXELS = max(\n",
    "    # seen cases (this is just empirical)\n",
    "    # batch_size * internal_multiplier_factor * input_nvoxels:\n",
    "    4 * (8 * 6) * (96**3),\n",
    "    8 * (16 * 6) * (320**2),  \n",
    "    3 * (16 * 6) * (800 * 928),\n",
    ")\n",
    "\n",
    "# this factor is specific to the gpu's memory size\n",
    "# to correct the fact that the max above was on an 8Gb-gpu\n",
    "known_hosts_factors = {\n",
    "    \"R7920-tomo\": 1,\n",
    "    \"akela.materiaux.ensmp.fr\": 5/8,\n",
    "    \"hathi.materiaux.ensmp.fr\": 5/8,\n",
    "    \"krilin.materiaux.ensmp.fr\": 5/8,\n",
    "}\n",
    "\n",
    "if n_gpus > 0 and hostname not in known_hosts_factors:\n",
    "    raise Exception(f\"Unkown {hostname=} with {n_gpus=} available. Please tell me how big the memory is relative to 8Gb.\")\n",
    "    \n",
    "MAX_INTERNAL_NVOXELS = int(known_hosts_factors[hostname] * MAX_INTERNAL_NVOXELS)\n",
    "\n",
    "logger.info(f\"{hostname=}\")\n",
    "logger.info(f\"{MAX_INTERNAL_NVOXELS=} ({humanize.intcomma(MAX_INTERNAL_NVOXELS)})\")\n",
    "\n",
    "estimation_volume[\"MAX_INTERNAL_NVOXELS\"] = MAX_INTERNAL_NVOXELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.opts.debug__save_figs:\n",
    "    figs_dir = estimation_volume.dir / \"debug_figs\"\n",
    "    logger.debug(f\"{figs_dir=}\")\n",
    "    figs_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `tf.distribute.OneDeviceStrategy` \n",
    "\n",
    "first just open the model to see that everything goes right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a distribution strategy to use both gpus (see https://www.tensorflow.org/guide/distributed_training)\n",
    "one_device = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\" if n_gpus > 0 else \"/cpu:0\")\n",
    "logger.debug(f\"{one_device=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    \n",
    "    try:\n",
    "        best_autosaved_model_path = tomo2seg_model.autosaved2_best_model_path  # it's a property\n",
    "    \n",
    "    except ValueError as ex:\n",
    "        \n",
    "        if ex.args[0] != \"min() arg is an empty sequence\":\n",
    "            raise ex\n",
    "        \n",
    "        logger.exception(ex)\n",
    "        logger.warning(f\"{tomo2seg_model.name=} did not use autosaved2 apparently, falling back to autosaved.\")\n",
    "        best_autosaved_model_path = tomo2seg_model.autosaved_model_path\n",
    "        \n",
    "    logger.info(f\"Loading model from autosaved file: {best_autosaved_model_path.name}\")\n",
    "    \n",
    "    model = tf.keras.models.load_model(\n",
    "        str(best_autosaved_model_path),\n",
    "        compile=False\n",
    "    )\n",
    "    \n",
    "    logger.debug(\"Changing the model's input type to accept any size of crop.\")\n",
    "    \n",
    "    in_ = model.layers[0]\n",
    "    in_shape = in_.input_shape[0]\n",
    "    input_n_channels = in_shape[-1]\n",
    "\n",
    "    logger.debug(f\"{input_n_channels=}\")\n",
    "    \n",
    "    if input_n_channels > 1:\n",
    "        \n",
    "        if args.model_type == Args.ModelType.input2halfd:\n",
    "            if len(in_shape) != 4:\n",
    "                raise f\"len({in_shape=}) > 4, so this model must be multi-channel. Not supported yet...\"\n",
    "        else:\n",
    "            raise NotImplementedError(f\"{input_n_channels=} > 1\")\n",
    "    \n",
    "    # make it capable of getting any dimension in the input\n",
    "    # \"-2\" = 1 for the batch size, 1 for the nb.channels\n",
    "    anysize_target_shape = (len(in_shape) - 2) * [None] + [input_n_channels] \n",
    "    logger.debug(f\"{anysize_target_shape=}\")\n",
    "    \n",
    "    anysize_input = layers.Input(\n",
    "        shape=anysize_target_shape,\n",
    "        name=\"input_any_image_size\"\n",
    "    )\n",
    "    logger.debug(f\"{anysize_input=}\")\n",
    "    \n",
    "    model.layers[0] = anysize_input\n",
    "    \n",
    "    # this doesn't really matter bc this script will not fit the model\n",
    "    optimizer = optimizers.Adam()\n",
    "    loss_func = keras_custom_loss.jaccard2_loss\n",
    "\n",
    "    logger.debug(\"Starting model compilation\")\n",
    "    model.compile(loss=loss_func, optimizer=optimizer)\n",
    "    logger.debug(\"Done!\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "with one_device.scope():\n",
    "    logger.info(f\"Loading model with {one_device.__class__.__name__}.\")\n",
    "    model = get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Loading data from disk at file: {volume.data_path.name}\")\n",
    "logger.debug(f\"{volume.data_path=}\")\n",
    "\n",
    "normalization_factor = volume_sequence.NORMALIZE_FACTORS[volume.metadata.dtype]\n",
    "\n",
    "logger.debug(f\"{normalization_factor=}\")\n",
    "\n",
    "data_volume = file_utils.HST_read(\n",
    "    str(volume.data_path),  # it doesn't accept paths...\n",
    "    autoparse_filename=False,  # the file names are not properly formatted\n",
    "    data_type=volume.metadata.dtype,\n",
    "    dims=volume.metadata.dimensions,\n",
    "    verbose=True,\n",
    ") / normalization_factor  # normalize\n",
    "\n",
    "logger.debug(f\"{data_volume.shape=}\")\n",
    "\n",
    "if partition is not None:\n",
    "    \n",
    "    logger.info(f\"Cutting data with {partition.alias=}\")\n",
    "    logger.debug(f\"{partition=}\")\n",
    "    \n",
    "    data_volume = partition.get_volume_partition(data_volume)\n",
    "\n",
    "else:\n",
    "    logger.debug(f\"No partition. The whole volume will be processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modify the data if necessary \n",
    "\n",
    "mostly the 2halfd..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.model_type == Args.ModelType.input2halfd:\n",
    "\n",
    "    try:\n",
    "        # this is to prevent running the padding twice in the notebook\n",
    "        half_pad\n",
    "\n",
    "    except NameError:\n",
    "\n",
    "            logger.warning(\"Modifying the data to add a 'reflect' half padding to the data. Only z-layers 2.5d models are supported!\")\n",
    "\n",
    "            nlayers_2halfd = model.layers[0].input_shape[0][-1]\n",
    "            \n",
    "            predicted_layer_idx_2halfd = nlayers_2halfd // 2\n",
    "            \n",
    "            slice_2halfd_data_predicted_layer = slice(predicted_layer_idx_2halfd, predicted_layer_idx_2halfd + 1)\n",
    "\n",
    "            logger.debug(f\"{nlayers_2halfd=}\")\n",
    "            logger.debug(f\"{predicted_layer_idx_2halfd=}\")\n",
    "            logger.debug(f\"{slice_2halfd_data_predicted_layer=}\")\n",
    "\n",
    "            assert nlayers_2halfd % 2 == 1, f\"{nlayers_2halfd=} should be an odd number\"\n",
    "\n",
    "            half_pad = (nlayers_2halfd - 1) // 2\n",
    "\n",
    "            logger.debug(f\"{half_pad=}\")\n",
    "\n",
    "            data_volume = np.pad(\n",
    "                data_volume, \n",
    "                pad_width=((0, 0), (0, 0), (half_pad, half_pad)),\n",
    "                mode=\"reflect\",\n",
    "            )\n",
    "\n",
    "            logger.debug(f\"{data_volume.shape=}\")    \n",
    "            estimation_volume[\"volume_is_padded\"] = True\n",
    "            estimation_volume[\"half_pad\"] = half_pad\n",
    "            \n",
    "    else:\n",
    "        logger.debug(\"Padding already applied.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_shape = data_volume.shape\n",
    "logger.info(f\"{volume_shape=}\")\n",
    "logger.info(f\"{data_volume.size=}  ({humanize.intword(data_volume.size)})\")\n",
    "estimation_volume[\"volume_shape\"] = volume_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how many voxels the gpus can take in a single batch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"{args.model_shape_min_multiple_requirement=}\")\n",
    "logger.info(f\"{MAX_INTERNAL_NVOXELS=} ({humanize.intcomma(MAX_INTERNAL_NVOXELS)})\")\n",
    "\n",
    "internal_nvoxel_factor = tomo2seg_utils.get_model_internal_nvoxel_factor(model)\n",
    "\n",
    "logger.debug(f\"{internal_nvoxel_factor=}\")\n",
    "\n",
    "max_batch_nvoxels = int(np.floor(MAX_INTERNAL_NVOXELS / internal_nvoxel_factor))\n",
    "\n",
    "logger.info(f\"{max_batch_nvoxels=} ({humanize.intcomma(max_batch_nvoxels)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "figure out the crop shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Using args.cropping_strategy={args.cropping_strategy.name} to find a suitable crop size.\")\n",
    "\n",
    "if args.cropping_strategy == Args.CroppingStrategy.maximum_size:\n",
    "    \n",
    "    crop_dims_multiple = process.get_largest_crop_multiple(\n",
    "        volume_shape, \n",
    "        multiple_of=args.model_shape_min_multiple_requirement\n",
    "    )\n",
    "\n",
    "elif args.cropping_strategy == Args.CroppingStrategy.maximum_size_reduced_overlap:\n",
    "    \n",
    "    # it's not necessarily the real minimum, just an easy way to get a big crop with less overlap\n",
    "    # get the largest multiple of the requirement above the dimension size / 2\n",
    "    # that will give a max overlap of 2 * MULTIPLE_REQUIREMENT - 1\n",
    "    # e.g. with MULTIPLE_REQUIREMENT = 16, the maximum overlap is 31\n",
    "    _mult = args.model_shape_min_multiple_requirement\n",
    "    crop_dims_multiple = tuple(\n",
    "        (1 + int((dim / 2) // _mult)) * _mult if dim % _mult != 0 else\n",
    "        dim\n",
    "        for dim in volume_shape\n",
    "    )\n",
    "    \n",
    "    def max_overlap(size):\n",
    "        overlap = int(2 * _mult - size % _mult)\n",
    "        return overlap if overlap < 32 else 0 \n",
    "    \n",
    "    logger.info(f\"the max overlap in each direction will be {tuple(max_overlap(s) for s in volume_shape)}\")\n",
    "    \n",
    "else:\n",
    "    raise ValueError(f\"{args.cropping_strategy=}\")\n",
    "\n",
    "logger.debug(f\"{crop_dims_multiple=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adjust the crop dimension if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it has to be multiple of 16 because of the 4 cascaded 2x2-strided 2x2-downsamplings in u-net\n",
    "if args.model_type == Args.ModelType.input2d:\n",
    "    crop_shape = (\n",
    "        crop_dims_multiple[0],\n",
    "        crop_dims_multiple[1],\n",
    "        1,\n",
    "    )\n",
    "\n",
    "elif args.model_type == Args.ModelType.input2halfd:\n",
    "    crop_shape = (\n",
    "        crop_dims_multiple[0],\n",
    "        crop_dims_multiple[1],\n",
    "        nlayers_2halfd,\n",
    "    )\n",
    "    \n",
    "elif args.model_type == Args.ModelType.input3d:\n",
    "    crop_shape = crop_dims_multiple\n",
    "    \n",
    "else:\n",
    "    raise ValueError(f\"{args.model_type=}\")\n",
    "\n",
    "logger.debug(f\"ideal {crop_shape=} for {args.model_type=} now let's see if the maximum number of voxels is ok...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_shape = reduce_dimensions(\n",
    "    crop_shape,\n",
    "    max_nvoxels=max_batch_nvoxels,\n",
    "    multiple_of=args.model_shape_min_multiple_requirement,\n",
    ")\n",
    "    \n",
    "logger.info(f\"{crop_shape=} \")\n",
    "\n",
    "crop_nvoxels = functools.reduce(operator.mul, crop_shape)\n",
    "\n",
    "logger.info(f\"{crop_nvoxels=} ({humanize.intcomma(crop_nvoxels)})\")\n",
    "\n",
    "max_batch_size_per_gpu = int(np.floor(max_batch_nvoxels / crop_nvoxels))\n",
    "\n",
    "logger.info(f\"{max_batch_size_per_gpu=}\")\n",
    "\n",
    "estimation_volume[\"crop_shape\"] = crop_shape\n",
    "estimation_volume[\"crop_nvoxels\"] = crop_nvoxels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps and coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates_in(axis_: int):\n",
    "    assert 0 <= axis_ <= 2, f\"{axis_=}\"\n",
    "    \n",
    "    vol_dim = volume_shape[axis_]\n",
    "    crop_dim = crop_shape[axis_]\n",
    "\n",
    "    start = 0\n",
    "\n",
    "    if axis_ == 2 and args.model_type == Args.ModelType.input2halfd:\n",
    "        n = vol_dim - 2 * half_pad\n",
    "        end = n - 1\n",
    "\n",
    "    elif axis_ == 2 and args.model_type == Args.ModelType.input2d:\n",
    "        assert crop_dim == 1, f\"{crop_dim=}\"\n",
    "        end = vol_dim - crop_dim  # vol_dim - 1\n",
    "        n = vol_dim  # vol_dim / 1 = vol_dim\n",
    "\n",
    "    else:\n",
    "        end = vol_dim - crop_dim\n",
    "        n = int(np.ceil(vol_dim / crop_dim))\n",
    "\n",
    "    return tuple(map(int, np.linspace(start, end, n)))\n",
    "\n",
    "# coordinates (xs, ys, and zs) of the front upper left corners of the crops\n",
    "x0s, y0s, z0s = tuple(\n",
    "    get_coordinates_in(axis_=axxis_)\n",
    "    for axxis_ in range(3)\n",
    ")\n",
    "\n",
    "logger.debug(x0s_ := f\"{min(x0s)=}, {max(x0s)=}, {len(x0s)=}\")\n",
    "logger.debug(y0s_ := f\"{min(y0s)=}, {max(y0s)=}, {len(y0s)=}\")\n",
    "logger.debug(z0s_ := f\"{min(z0s)=}, {max(z0s)=}, {len(z0s)=}\")\n",
    "\n",
    "ncrops = len(x0s) * len(y0s) * len(z0s)\n",
    "logger.debug(f\"{ncrops=}\")\n",
    "\n",
    "estimation_volume[\"x0s\"] = x0s_\n",
    "estimation_volume[\"y0s\"] = y0s_\n",
    "estimation_volume[\"z0s\"] = z0s_\n",
    "estimation_volume[\"ncrops\"] = ncrops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### crops coordinates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug(\"Generating the crop coordinates.\")\n",
    "\n",
    "crops_coordinates = np.array(\n",
    "    [\n",
    "        (\n",
    "            (x0, x0 + crop_shape[0]), \n",
    "            (y0, y0 + crop_shape[1]),\n",
    "            (z0, z0 + crop_shape[2]),\n",
    "        )\n",
    "        for x0, y0, z0 in itertools.product(x0s, y0s, z0s)\n",
    "    ], \n",
    "    dtype=tuple\n",
    ").reshape(len(x0s), len(y0s), len(z0s), 3, 2).astype(int)  # 3 = nb of dimenstions, 2 = (start, end)\n",
    "\n",
    "logger.debug(f\"{crops_coordinates.shape=}\")\n",
    "\n",
    "# 'F' reshapes with x varying fastest and z slowest\n",
    "crops_coordinates_sequential = crops_coordinates.reshape(-1, 3, 2, order='F')  \n",
    "\n",
    "logger.debug(f\"{crops_coordinates_sequential.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### orthogonal slices plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.opts.debug__save_figs:\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 2, figsize=(sz := 15, sz), dpi=120)\n",
    "    fig.set_tight_layout(True)\n",
    "    \n",
    "    display = viz.OrthogonalSlicesDisplay(\n",
    "        volume=data_volume,\n",
    "        volume_name=volume.fullname,\n",
    "    ).plot(axs=axs,)\n",
    "    \n",
    "    logger.info(f\"Saving figure {(figname := display.title + '.png')=}\")\n",
    "    display.fig_.savefig(\n",
    "        fname=figs_dir / figname,\n",
    "        dpi=200, format=\"png\",\n",
    "        metadata=display.metadata,\n",
    "    )\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_ijk = (0, 0, 0)\n",
    "i, j, k = crop_ijk\n",
    "crop_coords = crops_coordinates[i, j, k]\n",
    "\n",
    "logger.info(f\"Segmenting one crop for debug {crop_ijk=}\")\n",
    "\n",
    "crop_data = data_volume[tuple(slice(*coords_) for coords_ in crop_coords)]\n",
    "    \n",
    "logger.debug(f\"{crop_data.shape=}\")\n",
    "\n",
    "# [model] - i call it with a first crop bc if something goes wrong then the error\n",
    "# will appear here instead of in a loop\n",
    "\n",
    "modelin_target_shape = (1, crop_shape[0], crop_shape[1], crop_shape[2], 1)\n",
    "logger.debug(f\"{modelin_target_shape=}\")\n",
    "\n",
    "# modelin\n",
    "modelin = crop_data.reshape(modelin_target_shape) \n",
    "\n",
    "# modelout\n",
    "modelout = model.predict(\n",
    "    modelin, \n",
    "    batch_size=1,\n",
    "    steps=1,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "logger.debug(f\"{modelout.shape=}\")\n",
    "\n",
    "n_classes = modelout.shape[-1]\n",
    "\n",
    "assert n_classes == len(volume.metadata.labels), f\"{n_classes=} {len(volume.metadata.labels)=}\"\n",
    "\n",
    "if args.model_type == Args.ModelType.input2halfd:\n",
    "    crop_probas_target_shape = list(crop_shape[:2]) + [1] + [n_classes]\n",
    "    \n",
    "else:\n",
    "    crop_probas_target_shape = list(crop_shape) + [n_classes]\n",
    "    \n",
    "logger.debug(f\"{crop_probas_target_shape=}\")\n",
    "\n",
    "# probas\n",
    "crop_probas = modelout.reshape(crop_probas_target_shape).astype(args.probabilities_dtype)\n",
    "\n",
    "logger.debug(f\"{crop_probas.shape=}\")\n",
    "logger.debug(f\"{crop_probas.dtype=}\")\n",
    "\n",
    "# preds\n",
    "crop_preds = crop_probas.argmax(axis=-1).astype(np.int8)\n",
    "\n",
    "logger.debug(f\"{crop_preds.shape=}\")\n",
    "logger.debug(f\"{crop_preds.dtype=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.opts.debug__save_figs:\n",
    "    fig, axs = plt.subplots(\n",
    "        nrows=3, ncols=2,\n",
    "        figsize=(2 * (sz := 20), sz), \n",
    "        dpi=120,\n",
    "    )\n",
    "\n",
    "    viz_crop_data = (\n",
    "        crop_data[:, :, slice_2halfd_data_predicted_layer] \n",
    "        if args.model_type == Args.ModelType.input2halfd else \n",
    "        crop_data\n",
    "    )\n",
    "    \n",
    "    display = viz.OrthogonalSlicesPredictionDisplay(\n",
    "        volume_data=viz_crop_data,\n",
    "        volume_prediction=crop_preds,\n",
    "        n_classes=n_classes,\n",
    "        volume_name=volume.fullname + f\".debug.crop-{crop_ijk=}\",\n",
    "    ).plot(axs=axs,)\n",
    "\n",
    "    logger.info(f\"Saving figure {(figname := display.title + '.png')=}\")\n",
    "    display.fig_.savefig(\n",
    "        fname=figs_dir / figname,\n",
    "        format=\"png\",\n",
    "        metadata=display.metadata,\n",
    "    )       \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment a batch with `batch_size=n_gpus` (1 per device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Segmenting a batch with a single instance per gpu for debug.\")\n",
    "\n",
    "batch_size = max(1, n_gpus)\n",
    "logger.debug(f\"{batch_size=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirror = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with mirror.scope():\n",
    "    logger.info(f\"Loading model with {mirror.__class__.__name__}.\")\n",
    "    model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_coords = crops_coordinates_sequential[:batch_size]\n",
    "logger.debug(f\"{batch_coords.shape=}\")\n",
    "\n",
    "batch_slices = [\n",
    "    tuple(slice(*coords_) for coords_ in crop_coords)\n",
    "    for crop_coords in batch_coords\n",
    "]\n",
    "\n",
    "logger.debug(f\"{batch_slices=}\")\n",
    "\n",
    "batch_data = np.stack([\n",
    "    data_volume[slice_]\n",
    "    for slice_ in batch_slices\n",
    "], axis=0)\n",
    "\n",
    "logger.debug(f\"{batch_data.shape=}\")\n",
    "\n",
    "# [model] - now i call it with a first the mirror strategy to make sure it wont break\n",
    "\n",
    "batch_modelin_target_shape = tuple([batch_size] + list(modelin_target_shape[1:]))  # adjust nb. channels\n",
    "batch_probas_target_shape = tuple([batch_size] + list(crop_probas_target_shape))\n",
    "\n",
    "logger.debug(f\"{batch_modelin_target_shape=}\")\n",
    "logger.debug(f\"{batch_probas_target_shape=}\")\n",
    "\n",
    "# modelin\n",
    "modelin = batch_data.reshape(batch_modelin_target_shape) \n",
    "\n",
    "# modelout\n",
    "modelout = model.predict(\n",
    "    modelin, \n",
    "    batch_size=batch_size,\n",
    "    steps=1,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "logger.debug(f\"{modelout.shape=}\")\n",
    "\n",
    "# probas\n",
    "batch_probas = modelout.reshape(batch_probas_target_shape).astype(args.probabilities_dtype)\n",
    "\n",
    "logger.debug(f\"{batch_probas.shape=}\")\n",
    "logger.debug(f\"{batch_probas.dtype=}\")\n",
    "\n",
    "# preds\n",
    "batch_preds = batch_probas.argmax(axis=-1).astype(np.int8)\n",
    "\n",
    "logger.debug(f\"{batch_preds.shape=}\")\n",
    "logger.debug(f\"{batch_preds.dtype=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### segment batch with `batch_size = n_gpus * max_batch_size_per_gpu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Segmenting a batch with as many instances per gpu as possible for debug.\")\n",
    "\n",
    "batch_size = max(1, n_gpus) * max_batch_size_per_gpu\n",
    "logger.debug(f\"{batch_size=}\")\n",
    "\n",
    "if args.opts.override_batch_size is not None:\n",
    "    batch_size = args.opts.override_batch_size\n",
    "    logger.info(f\"{args.opts.override_batch_size=} give ==> replacing the {batch_size=}\")\n",
    "\n",
    "# usefull for debug \n",
    "batch_start = 0\n",
    "batch_end = batch_start + batch_size\n",
    "\n",
    "logger.debug(f\"{batch_start=}\")\n",
    "logger.debug(f\"{batch_end=}\")\n",
    "\n",
    "batch_coords = crops_coordinates_sequential[batch_start:batch_end]\n",
    "batch_slices = [\n",
    "    tuple(slice(*coords_) for coords_ in crop_coords)\n",
    "    for crop_coords in batch_coords\n",
    "]\n",
    "batch_data = np.stack([data_volume[slice_] for slice_ in batch_slices], axis=0)\n",
    "\n",
    "logger.debug(f\"{batch_data.shape=}\")\n",
    "\n",
    "batch_modelin_target_shape = tuple([batch_size] + list(modelin_target_shape[1:]))  # adjust nb. channels\n",
    "batch_probas_target_shape = tuple([batch_size] + list(crop_probas_target_shape))\n",
    "\n",
    "logger.debug(f\"{batch_modelin_target_shape=}\")\n",
    "logger.debug(f\"{batch_probas_target_shape=}\")\n",
    "\n",
    "# [model]\n",
    "# modelin\n",
    "modelin = batch_data.reshape(batch_modelin_target_shape) \n",
    "# modelout\n",
    "modelout = model.predict(\n",
    "    modelin, \n",
    "    batch_size=batch_size,\n",
    "    steps=1,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "logger.debug(f\"{modelout.shape=}\")\n",
    "\n",
    "# probas\n",
    "batch_probas = modelout.reshape(batch_probas_target_shape).astype(args.probabilities_dtype)\n",
    "\n",
    "logger.debug(f\"{batch_probas.shape=}\")\n",
    "\n",
    "# preds\n",
    "batch_preds = batch_probas.argmax(axis=-1).astype(np.int8)\n",
    "\n",
    "logger.debug(f\"{batch_preds.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DEBUG_FIGS = 10\n",
    "\n",
    "if args.opts.debug__save_figs:\n",
    "    \n",
    "    batch_modelout = modelout\n",
    "    \n",
    "    indices = (\n",
    "        range(batch_size) if batch_size <= MAX_DEBUG_FIGS else \n",
    "        map(int, np.linspace(0, batch_size, MAX_DEBUG_FIGS,)[:-1])\n",
    "    )\n",
    "    \n",
    "    for idx in indices:\n",
    "        crop_data__ = batch_data[idx]\n",
    "        crop_preds__ = batch_preds[idx]\n",
    "        \n",
    "        fig, axs = plt.subplots(\n",
    "            nrows=3, ncols=2,\n",
    "            figsize=(2 * (sz := 20), sz), \n",
    "            dpi=120,\n",
    "        )\n",
    "        \n",
    "        viz_crop_data = (\n",
    "            crop_data__[:, :, slice_2halfd_data_predicted_layer] \n",
    "            if args.model_type == Args.ModelType.input2halfd else \n",
    "            crop_data__\n",
    "        )\n",
    "        \n",
    "        display = viz.OrthogonalSlicesPredictionDisplay(\n",
    "            volume_data=viz_crop_data,\n",
    "            volume_prediction=crop_preds__,\n",
    "            n_classes=n_classes,\n",
    "            volume_name=volume.fullname + f\".debug.batch-segm.{idx=:04d}\",\n",
    "        ).plot(axs=axs,)\n",
    "\n",
    "        logger.info(f\"Saving figure {(figname := display.title + '.png')=}\")\n",
    "        display.fig_.savefig(\n",
    "            fname=figs_dir / figname,\n",
    "            format=\"png\",\n",
    "            metadata=display.metadata,\n",
    "        )       \n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rebuild the volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_batch_size = ncrops % batch_size\n",
    "\n",
    "if n_gpus > 1:\n",
    "    assert last_batch_size % n_gpus == 0, f\"{last_batch_size=}\"\n",
    "\n",
    "logger.debug(f\"{last_batch_size=}\")\n",
    "    \n",
    "niterations = int(np.floor(crops_coordinates_sequential.shape[0] / batch_size)) \n",
    "\n",
    "logger.debug(f\"{niterations=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.model_type == Args.ModelType.input2halfd:\n",
    "    proba_volume_target_shape = list(volume_shape[:2]) + [volume_shape[2] - 2 * half_pad] + [n_classes]\n",
    "    \n",
    "else:\n",
    "    proba_volume_target_shape = list(volume_shape) + [n_classes]\n",
    "\n",
    "redundancies_count_target_shape = proba_volume_target_shape[:3]\n",
    "    \n",
    "logger.debug(f\"{proba_volume_target_shape=}\")\n",
    "logger.debug(f\"{redundancies_count_target_shape=}\")\n",
    "\n",
    "proba_volume = np.zeros(proba_volume_target_shape, dtype=args.probabilities_dtype)\n",
    "logger.debug(f\"{proba_volume.shape=}\")\n",
    "\n",
    "redundancies_count = np.zeros(redundancies_count_target_shape, dtype=np.int8)  # only one channel\n",
    "logger.debug(f\"{redundancies_count.shape=}\")\n",
    "\n",
    "logger.debug(f\"{niterations=}\")\n",
    "\n",
    "def process_batch(batch_start_, batch_end_):\n",
    "    \n",
    "    batch_size_ = batch_end_ - batch_start_\n",
    "    \n",
    "    batch_modelin_target_shape_ = tuple([batch_size_] + list(modelin_target_shape[1:]))  # adjust nb. channels\n",
    "    batch_probas_target_shape_ = tuple([batch_size_] + list(crop_probas_target_shape))\n",
    "    \n",
    "    batch_coords = crops_coordinates_sequential[batch_start_:batch_end_]\n",
    "    batch_slices = [\n",
    "        tuple(slice(*coords_) for coords_ in crop_coords)\n",
    "        for crop_coords in batch_coords\n",
    "    ]\n",
    "    batch_data = np.stack([data_volume[slice_] for slice_ in batch_slices], axis=0)\n",
    "    \n",
    "    # [model] \n",
    "    batch_probas = model.predict(\n",
    "        batch_data.reshape(batch_modelin_target_shape_), \n",
    "        batch_size=batch_size_,\n",
    "        steps=1,\n",
    "    ).astype(args.probabilities_dtype).reshape(batch_probas_target_shape_)\n",
    "\n",
    "    for slice_, crop_proba in zip(batch_slices, batch_probas):\n",
    "        \n",
    "        if args.model_type == Args.ModelType.input2halfd:\n",
    "            # keep x and y as is, but reduce z\n",
    "            slice_ = tuple(\n",
    "                list(slice_[:2]) +\n",
    "                [slice(slice_[2].start, slice_[2].start + 1)]\n",
    "            )\n",
    "        \n",
    "        proba_volume[slice_] += crop_proba\n",
    "        redundancies_count[slice_] += np.ones(crop_proba.shape[:-1], dtype=np.int)\n",
    "        \n",
    "logger.debug(\"Predicting and summing up the crops' probabilities.\")\n",
    "for batch_idx in pbar(\n",
    "    range(niterations), \n",
    "    prefix=\"predict-and-sum-probas\", \n",
    "    max_value=niterations\n",
    "):\n",
    "    batch_start = batch_idx * batch_size\n",
    "    batch_end = batch_start + batch_size\n",
    "    \n",
    "    try:\n",
    "        process_batch(batch_start, batch_end)\n",
    " \n",
    "    except Exception as ex:\n",
    "        logger.debug(f\"{batch_idx=} {batch_start=} {batch_end=}\")\n",
    "        logger.exception(ex)\n",
    "        raise ex\n",
    "\n",
    "if last_batch_size > 0:\n",
    "    logger.info(\"Segmenting the last batch\")\n",
    "    \n",
    "    batch_start = niterations * batch_size\n",
    "    batch_end = batch_start + last_batch_size\n",
    "    \n",
    "    process_batch(batch_start, batch_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the min and max probas are coherent with the min/max redundancy\n",
    "min_proba_sum = proba_volume.min(axis=0).min(axis=0).min(axis=0)\n",
    "max_proba_sum = proba_volume.max(axis=0).max(axis=0).max(axis=0)\n",
    "min_redundancy = np.min(redundancies_count)\n",
    "max_redundancy = np.max(redundancies_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert min_redundancy >= 1, f\"{min_redundancy=}\"\n",
    "assert np.all(min_proba_sum >= 0), f\"{min_proba_sum=}\"\n",
    "assert np.all(max_proba_sum <= max_redundancy), f\"{max_proba_sum=} {max_redundancy=}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide each probability channel by the number of times it was summed (avg proba)\n",
    "logger.debug(f\"Dividing probability redundancies.\")\n",
    "\n",
    "for klass_idx in pbar(range(n_classes), max_value=n_classes, prefix=\"redundancies-per-class\"):\n",
    "    proba_volume[:, :, :, klass_idx] = proba_volume[:, :, :, klass_idx] / redundancies_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this makes it more stable so that the sum is 1\n",
    "proba_volume[:, :, :] /= proba_volume[:, :, :].sum(axis=-1, keepdims=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that proba distribs sum to 1\n",
    "min_proba = proba_volume.min(axis=0).min(axis=0).min(axis=0)\n",
    "max_proba = proba_volume.max(axis=0).max(axis=0).max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(min_proba >= 0), f\"{min_proba=}\"\n",
    "assert np.all(max_proba <= 1), f\"{max_proba=}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_distrib_proba_sum = proba_volume.sum(axis=-1).min()\n",
    "max_distrib_proba_sum = proba_volume.sum(axis=-1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isclose(min_distrib_proba_sum, 1, atol=.001), f\"{min_distrib_proba_sum=}\"\n",
    "assert np.isclose(max_distrib_proba_sum, 1, atol=.001), f\"{max_distrib_proba_sum=}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# proba 2 pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_volume = np.empty(proba_volume.shape[:-1], dtype=\"uint8\")\n",
    "\n",
    "np.argmax(proba_volume, axis=-1, out=pred_volume)\n",
    "\n",
    "logger.debug(f\"{pred_volume.shape=}\")\n",
    "logger.debug(f\"{pred_volume.min()=}\")\n",
    "logger.debug(f\"{pred_volume.max()=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.opts.debug__save_figs:\n",
    "    fig, axs = plt.subplots(\n",
    "        nrows=3, ncols=2,\n",
    "        figsize=(2 * (sz := 20), sz), \n",
    "        dpi=120,\n",
    "    )\n",
    "\n",
    "    viz_data = (\n",
    "        data_volume[:, :, half_pad:-half_pad] \n",
    "        if args.model_type == Args.ModelType.input2halfd else \n",
    "        data_volume\n",
    "    )\n",
    "\n",
    "    display = viz.OrthogonalSlicesPredictionDisplay(\n",
    "        volume_data=viz_data,\n",
    "        volume_prediction=pred_volume,\n",
    "        n_classes=n_classes,\n",
    "        volume_name=volume.fullname + f\".debug.predicted-volume.{idx=}\",\n",
    "    ).plot(axs=axs,)\n",
    "\n",
    "    logger.info(f\"Saving figure {(figname := display.title + '.png')=}\")\n",
    "    display.fig_.savefig(\n",
    "        fname=figs_dir / figname,\n",
    "        format=\"png\",\n",
    "        metadata=display.metadata,\n",
    "    )       \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug(f\"Writing probabilities on disk at `{estimation_volume.probabilities_path}`\")\n",
    "np.save(estimation_volume.probabilities_path, proba_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.opts.save_probas_by_class:\n",
    "    for klass_idx in volume.metadata.labels:\n",
    "        logger.debug(f\"Writing probabilities of class `{klass_idx}` on disk at `{(str_path := str(estimation_volume.get_class_probability_path(klass_idx)))=}`\")\n",
    "        file_utils.HST_write(proba_volume[:, :, :, klass_idx], str_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_volume.size * pred_volume.itemsize / 1024 ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug(f\"Writing predictions on disk at `{(str_path := str(estimation_volume.predictions_path))}`\")\n",
    "file_utils.HST_write(pred_volume, str_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one-z-slice-crops-locations.png\n",
    "\n",
    "not kept, search fro `one-z-slice-crops-locations.png` in `process-3d-crops-entire-2d-slice`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### debug__materialize_crops\n",
    "\n",
    "same for\n",
    "`debug__materialize_crops`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slack (:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slack.notify(\"process-volume finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_nb_name = \"process-volume-04-krilin92.ipynb\"\n",
    "\n",
    "this_dir = os.getcwd()\n",
    "save_nb_dir = str(estimation_volume.dir)\n",
    "\n",
    "logger.warning(f\"{this_nb_name=}\")\n",
    "logger.warning(f\"{this_dir=}\")\n",
    "logger.warning(f\"{save_nb_dir=}\")\n",
    "\n",
    "command = f\"jupyter nbconvert {this_dir}/{this_nb_name} --output-dir {save_nb_dir} --to html\"\n",
    "os.system(command)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
